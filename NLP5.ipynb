{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c19cbd6f-a641-4641-9e05-479fa74aeb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/dipankarsrirag/topic-modelling-on-emails\n"
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Авторизация\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Загрузка датасета\n",
    "api.dataset_download_files(\n",
    "    'dipankarsrirag/topic-modelling-on-emails',  # замените на реальное имя\n",
    "    path='./emails',\n",
    "    unzip=True  # автоматическая распаковка\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "811ff679-c853-4bdd-b3d5-91ab7071e6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rmdir /s /q \".\\\\emails\\\\Data\\\\Science\\\\.ipynb_checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66cf1fdc-85ab-4a9f-8139-1be1ecf0925c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\RAvakumov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Crime', 'Entertainment', 'Politics', 'Science']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "import pickle\n",
    "from nltk.corpus import stopwords, words\n",
    "import os\n",
    "import regex\n",
    "import random\n",
    "from nltk.tokenize import WordPunctTokenizer, word_tokenize\n",
    "from string import punctuation\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Загрузка таблиц токенизатора\n",
    "nltk.download('punkt_tab')\n",
    "   \n",
    "\n",
    "# Функция очистки и токенизации слов\n",
    "def clean_contents(contents):\n",
    "    text = str(contents).replace(\"\\\\n\", \" \").replace(\"\\\\r\", \" \").replace(\"\\\\\", \" \").replace(\">\", \" \").replace(\"<\", \" \").replace(\"\\t\", \" \").strip()\n",
    "    text = re.sub(r'\\S+@\\S+\\.\\S+', ' ', text)\n",
    "    text = text.replace(\"Reply-To:\", \" \")\n",
    "    text = text.replace(\"NNTP-Posting-Host:\", \" \")\n",
    "    text = re.sub(r'\\S+@\\S+\\.\\S+', ' ', text)\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', ' ', text)\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s\\.\\,\\!\\?\\-\\:]', ' ', text)\n",
    "\n",
    "    tokenized_word = []\n",
    "    for word in word_tokenize(text):\n",
    "        word = regex.sub(u'\\p{^Latin}', u'', word.lower())\n",
    "        tokenized_word.append(word)\n",
    "    tokenized_word = \" \".join(tokenized_word)\n",
    "    return tokenized_word\n",
    "\n",
    "# Загрузка файлов в память\n",
    "email_data = load_files(r\"emails/Data\")\n",
    "X, y, y_names = email_data.data, email_data.target, email_data.target_names\n",
    "\n",
    "# Вывод классов электронных писем\n",
    "print(y_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5363c16f-611a-41b5-ae57-9c176ad9b0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тексты email очищены\n"
     ]
    }
   ],
   "source": [
    "# Применение функции очистки и токенизации\n",
    "X_cleaned = [clean_contents(x) for x in X]\n",
    "\n",
    "# Формирование датафрейма\n",
    "df = pd.DataFrame(data= np.c_[X_cleaned, y], columns= ['content', 'class'])\n",
    "print(\"Тексты email очищены\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479fc607-56b8-4fe7-94c3-dd88494d6568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='class'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Удаление дубликатов, вывод соотношения классов\n",
    "df.drop_duplicates(subset=['content'], inplace=True, keep=False)\n",
    "df['class'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f285b156-e2e7-40b5-857e-6e14050d0d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные для Doc2Vec готовы\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных для Doc2Vec\n",
    "tagged_data = [TaggedDocument(words=_d.split(), tags=[str(i)]) for i, _d in enumerate(df['content'])]\n",
    "print(\"Данные для Doc2Vec готовы\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80372cd0-5a51-48cd-98fd-4561b25f5146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Построение словаря...\n",
      "Размер словаря: 32848\n",
      "Обучение модели...\n",
      "Эпоха 10/50 завершена\n",
      "Эпоха 20/50 завершена\n",
      "Эпоха 30/50 завершена\n",
      "Эпоха 40/50 завершена\n",
      "Эпоха 50/50 завершена\n",
      "Модель Doc2Vec построена и сохранена\n"
     ]
    }
   ],
   "source": [
    "def build_doc2vec(tagged_data, vector_size=200, epochs=50):\n",
    "    \n",
    "    model = Doc2Vec(\n",
    "        vector_size=vector_size,\n",
    "        min_count=2,           \n",
    "        window=10,             \n",
    "        sample=1e-5,\n",
    "        negative=10,\n",
    "        hs=0,\n",
    "        dm=0,                  \n",
    "        dbow_words=1,          \n",
    "        epochs=epochs,\n",
    "        alpha=0.025,\n",
    "        min_alpha=0.001,\n",
    "        workers=4\n",
    "    )\n",
    "\n",
    "    print(\"Построение словаря...\")\n",
    "    model.build_vocab(tagged_data)\n",
    "    \n",
    "    print(f\"Размер словаря: {len(model.wv.key_to_index)}\")\n",
    "\n",
    "    print(\"Обучение модели...\")\n",
    "    for epoch in range(epochs):\n",
    "        model.train(\n",
    "            tagged_data,\n",
    "            total_examples=model.corpus_count,\n",
    "            epochs=1\n",
    "        )\n",
    "        model.alpha -= 0.0004\n",
    "        model.min_alpha = model.alpha\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Эпоха {epoch + 1}/{epochs} завершена\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Строим модель\n",
    "doc_2_vec_model = build_doc2vec(tagged_data)\n",
    "\n",
    "# Сохранение Doc2Vec модели\n",
    "doc_2_vec_model.save(\"doc2vec_email_model.model\")\n",
    "print(\"Модель Doc2Vec построена и сохранена\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2d01771-4191-415b-9266-1b5a288c9b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность векторов Doc2Vec: (5631, 200)\n",
      "Размерность меток: (5631,)\n"
     ]
    }
   ],
   "source": [
    "doc_2_vec_model = Doc2Vec.load(\"doc2vec_email_model.model\")\n",
    "# Получаем векторные представления для всех документов\n",
    "X_vectors = np.array([doc_2_vec_model.dv[str(i)] for i in range(len(tagged_data))])\n",
    "y = df['class'].values.astype(int)\n",
    "\n",
    "# Проверяем размерности\n",
    "print(\"Размерность векторов Doc2Vec:\", X_vectors.shape)\n",
    "print(\"Размерность меток:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71fb97c8-49c8-4cc8-b8d9-ee36c5b3ff70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность train data: (4504, 200, 1)\n",
      "Размерность test data: (1127, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "# Классификатор CNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Нормализация данных\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_vectors)\n",
    "\n",
    "# Кодирование меток\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "num_classes = len(np.unique(y_encoded))\n",
    "\n",
    "# Преобразование в one-hot encoding\n",
    "y_categorical = to_categorical(y_encoded, num_classes=num_classes)\n",
    "\n",
    "# Разделение на обучающую и проверочную выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_categorical, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Форматирование для CNN (добавляем dimension для временных шагов)\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Проверяем размерность\n",
    "print(\"Размерность train data:\", X_train_cnn.shape)\n",
    "print(\"Размерность test data:\", X_test_cnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d60bc379-b194-4f60-941d-6678cd294c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAvakumov\\Documents\\Учеба\\foo\\NPL5\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3200</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">409,728</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m128\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m6,208\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m24,704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3200\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m409,728\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m130\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">450,562</span> (1.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m450,562\u001b[0m (1.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">449,858</span> (1.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m449,858\u001b[0m (1.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> (2.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m704\u001b[0m (2.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Функция построения модели CNN\n",
    "def create_cnn_doc2vec_model(input_shape, num_classes):\n",
    "    cnn_model = Sequential()\n",
    "\n",
    "    # Первый сверточный блок\n",
    "    cnn_model.add(Conv1D(filters=32, kernel_size=3, activation='relu',\n",
    "                    input_shape=input_shape, padding='same'))\n",
    "    cnn_model.add(BatchNormalization())\n",
    "    cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(Dropout(0.3))\n",
    "\n",
    "    # Второй сверточный блок\n",
    "    cnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'))\n",
    "    cnn_model.add(BatchNormalization())\n",
    "    cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(Dropout(0.4))\n",
    "\n",
    "    # Третий сверточный блок\n",
    "    cnn_model.add(Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "    cnn_model.add(BatchNormalization())\n",
    "    cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    # Выравнивание и полносвязные слои\n",
    "    cnn_model.add(Flatten())\n",
    "\n",
    "    cnn_model.add(Dense(128, activation='relu'))\n",
    "    cnn_model.add(BatchNormalization())\n",
    "    cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    cnn_model.add(Dense(64, activation='relu'))\n",
    "    cnn_model.add(Dropout(0.3))\n",
    "\n",
    "    # Выходной слой\n",
    "    cnn_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Компиляция модели\n",
    "    cnn_model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return cnn_model\n",
    "\n",
    "# Создание модели\n",
    "input_shape = (X_train_cnn.shape[1], X_train_cnn.shape[2])\n",
    "cnn_model = create_cnn_doc2vec_model(input_shape, num_classes)\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a9b6dd-501a-4a83-8bbf-b2a26d4a2a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.6256 - loss: 0.7839 - val_accuracy: 0.5150 - val_loss: 0.7123 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7266 - loss: 0.5771 - val_accuracy: 0.5649 - val_loss: 0.6635 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7685 - loss: 0.4967 - val_accuracy: 0.7525 - val_loss: 0.4946 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7960 - loss: 0.4456 - val_accuracy: 0.8224 - val_loss: 0.3737 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8185 - loss: 0.4057 - val_accuracy: 0.8635 - val_loss: 0.3296 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8357 - loss: 0.3879 - val_accuracy: 0.8824 - val_loss: 0.2896 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8379 - loss: 0.3625 - val_accuracy: 0.8868 - val_loss: 0.2587 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8579 - loss: 0.3314 - val_accuracy: 0.9012 - val_loss: 0.2402 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8687 - loss: 0.3107 - val_accuracy: 0.9034 - val_loss: 0.2288 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8743 - loss: 0.3034 - val_accuracy: 0.9234 - val_loss: 0.2149 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8956 - loss: 0.2708 - val_accuracy: 0.9290 - val_loss: 0.1956 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8965 - loss: 0.2585 - val_accuracy: 0.9312 - val_loss: 0.1974 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8901 - loss: 0.2665 - val_accuracy: 0.9356 - val_loss: 0.1843 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9034 - loss: 0.2298 - val_accuracy: 0.9423 - val_loss: 0.1717 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9037 - loss: 0.2427 - val_accuracy: 0.9489 - val_loss: 0.1691 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9170 - loss: 0.2074 - val_accuracy: 0.9445 - val_loss: 0.1670 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9106 - loss: 0.2152 - val_accuracy: 0.9489 - val_loss: 0.1551 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9203 - loss: 0.2080 - val_accuracy: 0.9456 - val_loss: 0.1691 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9220 - loss: 0.2033 - val_accuracy: 0.9512 - val_loss: 0.1521 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9312 - loss: 0.1836 - val_accuracy: 0.9512 - val_loss: 0.1509 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9242 - loss: 0.1866 - val_accuracy: 0.9478 - val_loss: 0.1506 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9306 - loss: 0.1710 - val_accuracy: 0.9478 - val_loss: 0.1479 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9337 - loss: 0.1634 - val_accuracy: 0.9512 - val_loss: 0.1415 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9348 - loss: 0.1693 - val_accuracy: 0.9523 - val_loss: 0.1391 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9387 - loss: 0.1585 - val_accuracy: 0.9534 - val_loss: 0.1358 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9459 - loss: 0.1444 - val_accuracy: 0.9534 - val_loss: 0.1330 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9395 - loss: 0.1517 - val_accuracy: 0.9489 - val_loss: 0.1374 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9487 - loss: 0.1295 - val_accuracy: 0.9512 - val_loss: 0.1346 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9414 - loss: 0.1463 - val_accuracy: 0.9501 - val_loss: 0.1289 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9439 - loss: 0.1461 - val_accuracy: 0.9523 - val_loss: 0.1285 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9498 - loss: 0.1263 - val_accuracy: 0.9567 - val_loss: 0.1244 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9498 - loss: 0.1344 - val_accuracy: 0.9512 - val_loss: 0.1309 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9509 - loss: 0.1253 - val_accuracy: 0.9567 - val_loss: 0.1212 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9528 - loss: 0.1225 - val_accuracy: 0.9578 - val_loss: 0.1206 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9603 - loss: 0.1147 - val_accuracy: 0.9512 - val_loss: 0.1287 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9553 - loss: 0.1190 - val_accuracy: 0.9612 - val_loss: 0.1192 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9542 - loss: 0.1158 - val_accuracy: 0.9589 - val_loss: 0.1147 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9561 - loss: 0.1197 - val_accuracy: 0.9567 - val_loss: 0.1139 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9575 - loss: 0.1165 - val_accuracy: 0.9578 - val_loss: 0.1160 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9614 - loss: 0.1005 - val_accuracy: 0.9567 - val_loss: 0.1172 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9620 - loss: 0.0988 - val_accuracy: 0.9589 - val_loss: 0.1109 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9648 - loss: 0.1002 - val_accuracy: 0.9589 - val_loss: 0.1058 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9614 - loss: 0.1047 - val_accuracy: 0.9578 - val_loss: 0.1144 - learning_rate: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9603 - loss: 0.1069 - val_accuracy: 0.9556 - val_loss: 0.1174 - learning_rate: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9642 - loss: 0.0925 - val_accuracy: 0.9612 - val_loss: 0.1136 - learning_rate: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9634 - loss: 0.0867 - val_accuracy: 0.9545 - val_loss: 0.1246 - learning_rate: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m109/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9678 - loss: 0.0893\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9664 - loss: 0.0947 - val_accuracy: 0.9545 - val_loss: 0.1154 - learning_rate: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9664 - loss: 0.0912 - val_accuracy: 0.9567 - val_loss: 0.1118 - learning_rate: 2.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9684 - loss: 0.0825 - val_accuracy: 0.9556 - val_loss: 0.1116 - learning_rate: 2.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9753 - loss: 0.0705 - val_accuracy: 0.9578 - val_loss: 0.1116 - learning_rate: 2.0000e-04\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Callback для раннего прерывания обучения\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8,\n",
    "                              restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Callback для уменьшения скорости обучения\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                             patience=5, min_lr=0.0001, verbose=1)\n",
    "\n",
    "# Запуск обучения\n",
    "history = cnn_model.fit(\n",
    "    X_train_cnn, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddf2b541-4035-45b9-a171-334b4d575042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фильтрация словаря...\n",
      "Размер словаря после фильтрации: 6001\n",
      "Создано 49861 последовательностей после фильтрации\n",
      "Размеры данных для обучения:\n",
      "X_doc_train: (39888, 200)\n",
      "X_word_train: (39888, 20)\n",
      "y_train: (39888, 6001)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, Dropout, Input, Concatenate\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "print(\"Фильтрация словаря...\")\n",
    "\n",
    "# Считаем частоту слов\n",
    "word_counts = Counter()\n",
    "for doc in tagged_data:\n",
    "    word_counts.update(doc.words)\n",
    "\n",
    "# Оставляем только самые частые слова\n",
    "top_n_words = 6000\n",
    "top_words = {word for word, count in word_counts.most_common(top_n_words)}\n",
    "vocab_size = len(top_words) + 1  \n",
    "\n",
    "# Создаем словарь word-to-index только для частых слов\n",
    "word_to_idx = {word: idx for idx, word in enumerate(top_words)}\n",
    "word_to_idx['<UNK>'] = len(word_to_idx)  # Токен для неизвестных слов\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "print(f\"Размер словаря после фильтрации: {vocab_size}\")\n",
    "\n",
    "max_sequence_length = 50  # Максимальная длина последовательности\n",
    "sequence_length = 20  # глубина последовательности\n",
    "\n",
    "X_sequences = []\n",
    "y_next_words = []\n",
    "\n",
    "for i, doc in enumerate(tagged_data):\n",
    "    words = doc.words\n",
    "    if len(words) > sequence_length:  # Пропускаем слишком короткие документы\n",
    "        # Берем вектор всего документа\n",
    "        doc_vector = X_vectors[i]\n",
    "        \n",
    "        # Создаем последовательности из N слов для предсказания N+1 слова\n",
    "        for j in range(sequence_length, min(len(words), max_sequence_length + sequence_length)):\n",
    "            # Берем последовательность из sequence_length предыдущих слов\n",
    "            sequence = words[j-sequence_length:j]\n",
    "            next_word = words[j]\n",
    "            \n",
    "            # Пропускаем последовательности с редкими словами\n",
    "            if all(word in top_words for word in sequence) and next_word in top_words:\n",
    "                # Преобразуем слова в индексы\n",
    "                sequence_idx = [word_to_idx[word] for word in sequence]\n",
    "                \n",
    "                X_sequences.append({\n",
    "                    'doc_vector': doc_vector,\n",
    "                    'word_sequence': sequence_idx  \n",
    "                })\n",
    "                y_next_words.append(word_to_idx[next_word])\n",
    "\n",
    "print(f\"Создано {len(X_sequences)} последовательностей после фильтрации\")\n",
    "\n",
    "# подготовка данных\n",
    "X_doc_vectors = np.array([seq['doc_vector'] for seq in X_sequences])\n",
    "X_word_sequences = np.array([seq['word_sequence'] for seq in X_sequences]) \n",
    "y_next_words = np.array(y_next_words)\n",
    "y_categorical = to_categorical(y_next_words, num_classes=vocab_size)\n",
    "\n",
    "# Разделение на тренировочную и тестовую выборку\n",
    "X_doc_train, X_doc_test, X_word_train, X_word_test, y_train, y_test = train_test_split(\n",
    "    X_doc_vectors, X_word_sequences, y_categorical, test_size=0.2, random_state=42  \n",
    ")\n",
    "\n",
    "print(f\"Размеры данных для обучения:\")\n",
    "print(f\"X_doc_train: {X_doc_train.shape}\")       \n",
    "print(f\"X_word_train: {X_word_train.shape}\")      \n",
    "print(f\"y_train: {y_train.shape}\")              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdb652af-e555-43a4-8618-7549eaf59082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создание модели LSTM для последовательностей...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ doc_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> │ doc_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ word_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">600,100</span> │ word_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,460,224</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">787,456</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                 │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6001</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,542,257</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ doc_input (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)               │          \u001b[38;5;34m20,100\u001b[0m │ doc_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ word_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m100\u001b[0m)           │         \u001b[38;5;34m600,100\u001b[0m │ word_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m100\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m200\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ repeat_vector[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m1,460,224\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │         \u001b[38;5;34m787,456\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                 │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6001\u001b[0m)              │       \u001b[38;5;34m1,542,257\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,410,137</span> (16.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,410,137\u001b[0m (16.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,410,137</span> (16.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,410,137\u001b[0m (16.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Dense, Embedding, Dropout, Input, Concatenate, RepeatVector\n",
    "\n",
    "print(\"Создание модели LSTM для последовательностей...\")\n",
    "\n",
    "sequence_length = X_word_train.shape[1]  # Автоматически получаем длину последовательности \n",
    "\n",
    "# Вход для вектора документа\n",
    "doc_input = Input(shape=(200,), name='doc_input')\n",
    "doc_dense = Dense(100, activation='relu')(doc_input)\n",
    "doc_dropout = Dropout(0.3)(doc_dense)\n",
    "\n",
    "word_input = Input(shape=(sequence_length,), name='word_input') \n",
    "word_embedding = Embedding(input_dim=vocab_size, output_dim=100)(word_input) \n",
    "\n",
    "# Размножаем вектор документа для каждого элемента последовательности\n",
    "doc_repeated = RepeatVector(sequence_length)(doc_dropout) \n",
    "\n",
    "# Объединяем эмбеддинги слов и вектор документа\n",
    "merged = Concatenate(axis=-1)([word_embedding, doc_repeated])\n",
    "\n",
    "# LSTM слои\n",
    "lstm_layer1 = LSTM(512, return_sequences=True, dropout=0.3)(merged)\n",
    "lstm_layer2 = LSTM(256, dropout=0.3)(lstm_layer1) \n",
    "\n",
    "# Выходной слой\n",
    "output = Dense(vocab_size, activation='softmax')(lstm_layer2)\n",
    "\n",
    "# LSTM-модель\n",
    "model = Model(inputs=[doc_input, word_input], outputs=output)\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d78cfd4-a938-4626-a211-29630c85e6bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_doc_train shape: (39888, 200)\n",
      "X_word_train shape: (39888, 20)\n",
      "y_train shape: (39888, 6001)\n",
      "Epoch 1/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 190ms/step - accuracy: 0.0562 - loss: 6.7688 - val_accuracy: 0.0536 - val_loss: 6.6016 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 206ms/step - accuracy: 0.0561 - loss: 6.4829 - val_accuracy: 0.0536 - val_loss: 6.6107 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 182ms/step - accuracy: 0.0573 - loss: 6.4159 - val_accuracy: 0.0634 - val_loss: 6.4713 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 180ms/step - accuracy: 0.0762 - loss: 6.1635 - val_accuracy: 0.0756 - val_loss: 6.2638 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 181ms/step - accuracy: 0.0900 - loss: 5.8967 - val_accuracy: 0.0842 - val_loss: 6.1114 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 194ms/step - accuracy: 0.1011 - loss: 5.6656 - val_accuracy: 0.0961 - val_loss: 6.0059 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 183ms/step - accuracy: 0.1153 - loss: 5.4574 - val_accuracy: 0.1041 - val_loss: 5.9459 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 217ms/step - accuracy: 0.1258 - loss: 5.2645 - val_accuracy: 0.1138 - val_loss: 5.8706 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 178ms/step - accuracy: 0.1385 - loss: 5.0800 - val_accuracy: 0.1191 - val_loss: 5.8076 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 185ms/step - accuracy: 0.1493 - loss: 4.9301 - val_accuracy: 0.1220 - val_loss: 5.7702 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 177ms/step - accuracy: 0.1597 - loss: 4.7328 - val_accuracy: 0.1379 - val_loss: 5.7101 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 178ms/step - accuracy: 0.1773 - loss: 4.5547 - val_accuracy: 0.1483 - val_loss: 5.6693 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 184ms/step - accuracy: 0.1935 - loss: 4.3817 - val_accuracy: 0.1582 - val_loss: 5.6275 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 209ms/step - accuracy: 0.2087 - loss: 4.2084 - val_accuracy: 0.1698 - val_loss: 5.6093 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 182ms/step - accuracy: 0.2299 - loss: 4.0415 - val_accuracy: 0.1789 - val_loss: 5.5824 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 196ms/step - accuracy: 0.2495 - loss: 3.8831 - val_accuracy: 0.1923 - val_loss: 5.5749 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 181ms/step - accuracy: 0.2704 - loss: 3.7294 - val_accuracy: 0.2005 - val_loss: 5.5681 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 189ms/step - accuracy: 0.2901 - loss: 3.5871 - val_accuracy: 0.2103 - val_loss: 5.5360 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 188ms/step - accuracy: 0.3112 - loss: 3.4440 - val_accuracy: 0.2207 - val_loss: 5.5338 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 194ms/step - accuracy: 0.3306 - loss: 3.3106 - val_accuracy: 0.2362 - val_loss: 5.5349 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 205ms/step - accuracy: 0.3536 - loss: 3.1821 - val_accuracy: 0.2441 - val_loss: 5.5496 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 211ms/step - accuracy: 0.3732 - loss: 3.0579 - val_accuracy: 0.2581 - val_loss: 5.5506 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 188ms/step - accuracy: 0.3930 - loss: 2.9373 - val_accuracy: 0.2653 - val_loss: 5.5509 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.4224 - loss: 2.7862\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 174ms/step - accuracy: 0.4157 - loss: 2.8294 - val_accuracy: 0.2712 - val_loss: 5.5770 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 184ms/step - accuracy: 0.4600 - loss: 2.5961 - val_accuracy: 0.2813 - val_loss: 5.5483 - learning_rate: 2.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 195ms/step - accuracy: 0.4711 - loss: 2.5446 - val_accuracy: 0.2857 - val_loss: 5.5475 - learning_rate: 2.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 195ms/step - accuracy: 0.4774 - loss: 2.5111 - val_accuracy: 0.2875 - val_loss: 5.5487 - learning_rate: 2.0000e-04\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "print(f\"X_doc_train shape: {X_doc_train.shape}\")\n",
    "print(f\"X_word_train shape: {X_word_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "# Callback для раннего прерывания обучения\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8,\n",
    "                              restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Callback для уменьшения скорости обучения\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                             patience=5, min_lr=0.0001, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    [X_doc_train, X_word_train],\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=50,  \n",
    "    validation_data=([X_doc_test, X_word_test], y_test),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7790a79e-531c-404a-bd2e-17e479114360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM-модель сохранена как lstm_model.h5\n"
     ]
    }
   ],
   "source": [
    "model.save('lstm_model.h5')\n",
    "print(\"LSTM-модель сохранена как lstm_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "347a852b-285e-44fd-9f62-6ee8387d34bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание класса вектора\n",
    "def classify(doc_vector, cnn_model):\n",
    "\n",
    "    doc_vector_scaled = scaler.transform([doc_vector])\n",
    "    doc_vector_cnn = doc_vector_scaled.reshape(1, doc_vector_scaled.shape[1], 1)\n",
    "   \n",
    "    predictions = cnn_model.predict(doc_vector_cnn, verbose=0)\n",
    "    predicted_class_idx = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_class = label_encoder.inverse_transform([predicted_class_idx])[0]\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "017ddbc3-65dc-4480-ad7a-0e5f81f58edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация текста с использованием CNN-классификатора\n",
    "def generate_text_with_cnn(model, cnn_model, start_sequence, num_words=20, \n",
    "                          temperature=1.0, top_k=10, class_id=2):\n",
    "\n",
    "    # Выбираем вектор документа нужного класса\n",
    "    class_indices = np.where(y == class_id)[0]\n",
    "    if len(class_indices) == 0:\n",
    "        class_indices = [0]\n",
    "    \n",
    "    doc_vector = X_vectors[random.choice(class_indices)]\n",
    "    \n",
    "    # Предсказываем класс документа с помощью CNN\n",
    "    predicted_class = classify(doc_vector, cnn_model)\n",
    "    print(f\"CNN предсказал класс: {predicted_class}, ожидаемый: {class_id}\")\n",
    "    \n",
    "    # Если CNN не согласен с выбранным классом, ищем другой документ\n",
    "    if predicted_class != class_id:\n",
    "        print(\"Ищем документ, который CNN классифицирует правильно...\")\n",
    "        found = False\n",
    "        for attempt in range(100):  # Пробуем 10 раз\n",
    "            doc_vector = X_vectors[random.choice(class_indices)]\n",
    "            predicted_class = classify(doc_vector, cnn_model)\n",
    "            if predicted_class == class_id:\n",
    "                found = True\n",
    "                print(f\"Найден подходящий документ на попытке {attempt + 1}\")\n",
    "                break\n",
    "        \n",
    "        if not found:\n",
    "            print(\"Не удалось найти документ нужного класса, используем любой\")\n",
    "    \n",
    "    # Генерация текста\n",
    "    current_sequence = [word_to_idx.get(word, word_to_idx['<UNK>']) \n",
    "                       for word in start_sequence]\n",
    "    generated_text = start_sequence.copy()\n",
    "    \n",
    "    # Убедимся, что начальная последовательность правильной длины\n",
    "    if len(current_sequence) > sequence_length:\n",
    "        current_sequence = current_sequence[-sequence_length:]\n",
    "    elif len(current_sequence) < sequence_length:\n",
    "        # Дополняем до нужной длины\n",
    "        padding = [word_to_idx['<UNK>']] * (sequence_length - len(current_sequence))\n",
    "        current_sequence = padding + current_sequence\n",
    "    \n",
    "    print(f\"Начальная последовательность (индексы): {current_sequence}\")\n",
    "    print(f\"Начальная последовательность (слова): {start_sequence}\")\n",
    "    \n",
    "    for i in range(num_words):\n",
    "        # Используем оригинальный doc2vec вектор\n",
    "        doc_vector_reshaped = doc_vector.reshape(1, -1)  # Форма (1, 200)\n",
    "        sequence_reshaped = np.array([current_sequence]).reshape(1, -1)  # Форма (1, sequence_length)\n",
    "        \n",
    "        # Проверяем формы перед предсказанием\n",
    "        print(f\"Итерация {i+1}: doc_vector shape: {doc_vector_reshaped.shape}, sequence shape: {sequence_reshaped.shape}\")\n",
    "        \n",
    "        predictions = model.predict([doc_vector_reshaped, sequence_reshaped], verbose=0)\n",
    "        top_k_idx = np.argsort(predictions[0])[-top_k:]\n",
    "        top_k_probs = predictions[0][top_k_idx]\n",
    "        \n",
    "        # Применяем temperature\n",
    "        top_k_probs = np.log(top_k_probs + 1e-7) / temperature\n",
    "        exp_probs = np.exp(top_k_probs)\n",
    "        top_k_probs_normalized = exp_probs / np.sum(exp_probs)\n",
    "        \n",
    "        # Выбираем следующее слово\n",
    "        next_word_idx = np.random.choice(top_k_idx, p=top_k_probs_normalized)\n",
    "        next_word = idx_to_word.get(next_word_idx, '<UNK>')\n",
    "        \n",
    "        generated_text.append(next_word)\n",
    "        current_sequence.append(next_word_idx)\n",
    "        current_sequence = current_sequence[1:]  # Сохраняем фиксированную длину\n",
    "        \n",
    "        print(f\"Сгенерировано: '{next_word}' (индекс: {next_word_idx})\")\n",
    "    \n",
    "    print(\"Генерация завершена!\")\n",
    "    return ' '.join(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3ed50c1-4694-4c6b-8819-07fef12ba40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN предсказал класс: 3, ожидаемый: 3\n",
      "Начальная последовательность (индексы): [6000, 6000, 6000, 6000, 6000, 6000, 6000, 5439, 5397, 1866, 5018, 5439, 5691, 3427, 1755, 5805, 4631, 2039, 15, 1785]\n",
      "Начальная последовательность (слова): ['This', 'raises', 'the', 'question', 'of', 'how', 'the', 'two', 'phones', 'agree', 'on', 'a', 'communications', 'encryption', 'key']\n",
      "Итерация 1: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'the' (индекс: 5439)\n",
      "Итерация 2: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'same' (индекс: 1387)\n",
      "Итерация 3: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'module' (индекс: 4995)\n",
      "Итерация 4: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'to' (индекс: 3038)\n",
      "Итерация 5: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'the' (индекс: 5439)\n",
      "Итерация 6: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'same' (индекс: 1387)\n",
      "Итерация 7: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'logic' (индекс: 5988)\n",
      "Итерация 8: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'is' (индекс: 1459)\n",
      "Итерация 9: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'the' (индекс: 5439)\n",
      "Итерация 10: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'transistor' (индекс: 5709)\n",
      "Генерация завершена!\n",
      "Результат:\n",
      "This raises the question of how the two phones agree on a communications encryption key the same module to the same logic is the transistor\n"
     ]
    }
   ],
   "source": [
    "# Научный текст\n",
    "science_sequence = [\"This\", \"raises\", \"the\", \"question\", \"of\", \"how\", \"the\", \"two\", \"phones\", \"agree\", \"on\", \"a\", \"communications\",\n",
    "                    \"encryption\", \"key\"]\n",
    "\n",
    "generated_text = generate_text_with_cnn(\n",
    "        model=model,\n",
    "        cnn_model=cnn_model,\n",
    "        start_sequence=science_sequence,\n",
    "        class_id=3,\n",
    "        num_words=10,\n",
    "        temperature=0.3\n",
    "    )\n",
    "print(\"Результат:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7189121-03f8-4eba-9c01-c979475711ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN предсказал класс: 2, ожидаемый: 2\n",
      "Начальная последовательность (индексы): [6000, 6000, 6000, 6000, 6000, 6000, 1274, 6000, 709, 5439, 399, 3038, 3341, 71, 793, 4373, 940, 2354, 6000, 1860]\n",
      "Начальная последовательность (слова): ['I', 'suspect', 'Clinton', 'gave', 'the', 'order', 'to', 'get', 'someone', 'or', 'some', 'group', 'with', 'assualt', 'weapons']\n",
      "Итерация 1: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'we' (индекс: 4325)\n",
      "Итерация 2: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'can' (индекс: 4140)\n",
      "Итерация 3: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'not' (индекс: 850)\n",
      "Итерация 4: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'be' (индекс: 2322)\n",
      "Итерация 5: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'taken' (индекс: 733)\n",
      "Итерация 6: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'to' (индекс: 3038)\n",
      "Итерация 7: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'say' (индекс: 2916)\n",
      "Итерация 8: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'that' (индекс: 5780)\n",
      "Итерация 9: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'the' (индекс: 5439)\n",
      "Итерация 10: doc_vector shape: (1, 200), sequence shape: (1, 20)\n",
      "Сгенерировано: 'circumstances' (индекс: 1854)\n",
      "Генерация завершена!\n",
      "Результат:\n",
      "I suspect Clinton gave the order to get someone or some group with assualt weapons we can not be taken to say that the circumstances\n"
     ]
    }
   ],
   "source": [
    "# Политический текст\n",
    "political_sequence = [\n",
    "    \"I\", \"suspect\", \"Clinton\", \"gave\", \"the\", \"order\", \"to\", \"get\", \n",
    "    \"someone\", \"or\", \"some\", \"group\", \"with\", \"assualt\", \"weapons\"\n",
    "]\n",
    "\n",
    "generated_text = generate_text_with_cnn(\n",
    "        model=model,\n",
    "        cnn_model=cnn_model,\n",
    "        start_sequence=political_sequence,\n",
    "        class_id=2,\n",
    "        num_words=10,\n",
    "        temperature=0.3\n",
    "    )\n",
    "print(\"Результат:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af53fa1d-0ed5-4a3f-96db-c852090ce64a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
